{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b80d37e6",
   "metadata": {},
   "source": [
    "# Day 7: AI-Assisted IaC Code Review - Enhanced Workflow\n",
    "\n",
    "This notebook demonstrates a workflow for reviewing Terraform IaC files using both static analysis tools and a Large Language Model (LLM). Outputs are saved and compared to highlight the strengths of each approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f39c9b",
   "metadata": {},
   "source": [
    "## 1. Run Static Analysis with tfsec and checkov\n",
    "\n",
    "The following cells will run tfsec and checkov on all Terraform files in the project and save their outputs to markdown files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83919c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 Terraform files:\n",
      "../../..\\IT\\AWS Architecture using Terraform\\provider.tf\n",
      "../../..\\IT\\AWS Architecture using Terraform\\sg_asg_alb.tf\n",
      "../../..\\IT\\AWS Architecture using Terraform\\vpc.tf\n",
      "../../..\\IT\\Cloud-Resource-Optimization-Tool\\terraform\\main.tf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Find all .tf files in the workspace\n",
    "terraform_files = []\n",
    "for root, dirs, files in os.walk('../../..'):\n",
    "    for file in files:\n",
    "        if file.endswith('.tf'):\n",
    "            terraform_files.append(os.path.join(root, file))\n",
    "\n",
    "print(f\"Found {len(terraform_files)} Terraform files:\")\n",
    "for tf_file in terraform_files:\n",
    "    print(tf_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74fe3da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfsec output saved to c:\\Users\\behip\\Documents\\Work\\IT\\30-Days-of-AI-in-Devops-SRE-Challenge-\\Day 7 - AI-Assisted IaC Code Review\\Iac analysis\\provider.tf_tfsec.md\n",
      "tfsec output saved to c:\\Users\\behip\\Documents\\Work\\IT\\30-Days-of-AI-in-Devops-SRE-Challenge-\\Day 7 - AI-Assisted IaC Code Review\\Iac analysis\\sg_asg_alb.tf_tfsec.md\n",
      "tfsec output saved to c:\\Users\\behip\\Documents\\Work\\IT\\30-Days-of-AI-in-Devops-SRE-Challenge-\\Day 7 - AI-Assisted IaC Code Review\\Iac analysis\\sg_asg_alb.tf_tfsec.md\n",
      "tfsec output saved to c:\\Users\\behip\\Documents\\Work\\IT\\30-Days-of-AI-in-Devops-SRE-Challenge-\\Day 7 - AI-Assisted IaC Code Review\\Iac analysis\\vpc.tf_tfsec.md\n",
      "tfsec output saved to c:\\Users\\behip\\Documents\\Work\\IT\\30-Days-of-AI-in-Devops-SRE-Challenge-\\Day 7 - AI-Assisted IaC Code Review\\Iac analysis\\vpc.tf_tfsec.md\n",
      "tfsec output saved to c:\\Users\\behip\\Documents\\Work\\IT\\30-Days-of-AI-in-Devops-SRE-Challenge-\\Day 7 - AI-Assisted IaC Code Review\\Iac analysis\\main.tf_tfsec.md\n",
      "tfsec output saved to c:\\Users\\behip\\Documents\\Work\\IT\\30-Days-of-AI-in-Devops-SRE-Challenge-\\Day 7 - AI-Assisted IaC Code Review\\Iac analysis\\main.tf_tfsec.md\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "output_dir = os.path.join(os.getcwd(), \"Iac analysis\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for tf_file in terraform_files:\n",
    "    base_name = os.path.basename(tf_file)\n",
    "    tfsec_dir = os.path.dirname(tf_file)\n",
    "    output_file = os.path.join(output_dir, base_name + '_tfsec.md')\n",
    "    try:\n",
    "        result = subprocess.run([\"tfsec\", tfsec_dir], capture_output=True, text=True)\n",
    "        output = result.stdout\n",
    "    except FileNotFoundError:\n",
    "        output = \"tfsec not installed or not found in PATH. Please install tfsec to run static analysis.\"\n",
    "    except Exception as e:\n",
    "        output = f\"tfsec error: {e}\"\n",
    "    with open(output_file, \"w\") as f:\n",
    "        f.write(f\"# tfsec Analysis for {tf_file}\\n\\n\")\n",
    "        f.write(output)\n",
    "    print(f\"tfsec output saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324307a4",
   "metadata": {},
   "source": [
    "## 2. LLM Review of Terraform Files (Ollama)\n",
    "\n",
    "The following cell sends each Terraform file to an LLM (Ollama) for review and saves the feedback to markdown files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93d26fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing only: ['../../..\\\\IT\\\\AWS Architecture using Terraform\\\\vpc.tf']\n"
     ]
    }
   ],
   "source": [
    "# TEMPORARY: Only analyze vpc.tf for faster testing\n",
    "# Remove or comment out this cell to analyze all Terraform files\n",
    "terraform_files = [tf for tf in terraform_files if os.path.basename(tf) == 'vpc.tf']\n",
    "print(f\"Analyzing only: {terraform_files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "827f0926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama review saved to c:\\Users\\behip\\Documents\\Work\\IT\\30-Days-of-AI-in-Devops-SRE-Challenge-\\Day 7 - AI-Assisted IaC Code Review\\Iac analysis\\vpc.tf_ollama_review.md\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "OLLAMA_URL = \"http://localhost:11434/api/generate\"\n",
    "OLLAMA_MODEL = \"codellama\"  # Change to your preferred model\n",
    "\n",
    "review_prompt_template = (\n",
    "    \"You are a senior DevOps engineer and security reviewer. \"\n",
    "    \"Carefully review the following Terraform code for security vulnerabilities, misconfigurations, performance issues, compliance gaps, and best-practice violations. \"\n",
    "    \"Provide actionable feedback, specific recommendations, and highlight any critical, high, medium, or low severity issues you find in the code itself. \"\n",
    "    \"Organize your feedback into sections: Security, Performance, Compliance, and Best Practices. \"\n",
    "    \"For each issue, provide a clear explanation, severity, and actionable improvement.\\n\\n\"\n",
    "    \"Terraform code:\\n{terraform_code}\\n\"\n",
    ")\n",
    "\n",
    "output_dir = os.path.join(os.getcwd(), \"Iac analysis\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for tf_file in terraform_files:\n",
    "    base_name = os.path.basename(tf_file)\n",
    "    with open(tf_file, \"r\") as f:\n",
    "        terraform_code = f.read()\n",
    "    review_prompt = review_prompt_template.format(terraform_code=terraform_code)\n",
    "    payload = {\n",
    "        \"model\": OLLAMA_MODEL,\n",
    "        \"prompt\": review_prompt,\n",
    "        \"stream\": False\n",
    "    }\n",
    "    response = requests.post(OLLAMA_URL, json=payload)\n",
    "    feedback = response.json().get(\"response\", \"No feedback received.\")\n",
    "    output_file = os.path.join(output_dir, base_name + \"_ollama_review.md\")\n",
    "    with open(output_file, \"w\") as f:\n",
    "        f.write(f\"# Ollama LLM Review for {tf_file}\\n\\n\")\n",
    "        f.write(feedback)\n",
    "    print(f\"Ollama review saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6640806f",
   "metadata": {},
   "source": [
    "## 3. Comparison: tfsec vs Ollama LLM Review for vpc.tf\n",
    "\n",
    "### tfsec Output Highlights\n",
    "- tfsec provides automated static analysis, flagging security vulnerabilities, misconfigurations, and best-practice violations based on predefined rules.\n",
    "- The output is structured, listing passed checks and detected issues with severity levels and recommendations.\n",
    "- tfsec excels at quickly identifying known patterns and compliance gaps, but may miss context-specific or nuanced issues.\n",
    "\n",
    "### Ollama LLM Output Highlights\n",
    "- Ollama (LLM) reviews the Terraform code directly, offering human-like feedback and deeper reasoning.\n",
    "- The LLM can identify issues missed by static analysis, provide context-aware suggestions, and explain the rationale behind recommendations.\n",
    "- Feedback is organized into sections (Security, Performance, Compliance, Best Practices) and is more actionable and readable.\n",
    "- Ollama is used in this project because it is free and runs locally, making it accessible for experimentation and learning.\n",
    "- For even better results, one can use commercial LLMs such as OpenAI's GPT models via API keys, which may provide more advanced analysis and richer feedback.\n",
    "\n",
    "### Key Differences\n",
    "- tfsec is rule-based and deterministic; Ollama is context-aware and can reason about code beyond static rules.\n",
    "- Ollama may catch subtle or emerging risks, while tfsec is limited to its rule set.\n",
    "- Combining both approaches provides broader coverage: tfsec for quick checks, Ollama for deeper review.\n",
    "\n",
    "### Conclusion\n",
    "Using both tfsec and Ollama LLM for IaC code review offers complementary strengths. tfsec ensures baseline security and compliance, while Ollama provides expert-level, context-sensitive feedback. For best results, use tfsec to catch common issues and LLMs to uncover complex, nuanced, or human-centric risks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
